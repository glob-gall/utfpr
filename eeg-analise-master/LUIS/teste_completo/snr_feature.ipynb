{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração da característica de relação sinal-ruído de dados de EEG\n",
    "\n",
    "A ideia é utilizar dados fictícios de ruído e sinal \"bom\"., para criarmos a relação dos dois sinais e obter como resultado um sinal de interesse \"limpo\".\n",
    "\n",
    "A partir deste sinal, podemos no contexto de caracterização de foco, ainda extrair os rítmos cerebrais ou então classificar sinais com a presença ou não de foco, de forma que as amostras de sinais extraídas de um buffer sejam rotuladas com com a presença ou não de foco.\n",
    "\n",
    "Esta atividade pode ser realizada em conjunto com um classificador comumente utilizado, como é o caso do SVM. Neste caso, uma porcetagem das amostras são utilizadas para treino e o restante para teste (p.e. 30 e 70% respectivamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dados fictícios\n",
    "# pensando em um vídeo de 10 minutos, com uma taxa de amostragem de 250 Hz\n",
    "#   teremos 10 * 60 * 250 = 150.000 amostras (sinal com foco)\n",
    "#   teremos 1 * 60 * 250 = 15.000 amostras (basal)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "shape = (150000, 8)\n",
    "data_focus = np.random.normal(loc=0, scale=10, size=shape).astype(np.float32)\n",
    "\n",
    "shape = (15000, 8)\n",
    "data_base = np.random.normal(loc=0, scale=10, size=shape).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.779752+1.3020833e-07j)\n",
      "[np.complex64(-4.7236996-5.2083334e-07j), np.complex64(-1.8819275+0j), np.complex64(9.877919+5.2083334e-07j), np.complex64(8.014124+1.0416667e-06j), np.complex64(-1.8130136-5.2083334e-07j), np.complex64(-9.682887+0j), np.complex64(5.053993-5.2083334e-07j), np.complex64(-11.082524+1.0416667e-06j)]\n"
     ]
    }
   ],
   "source": [
    "# Estimando o ruído de fundo (utilizando o sinal basal)\n",
    "\n",
    "# armazena uma lista com as médias de potência para cada canal\n",
    "noise_power = []\n",
    "for channel_data in data_base.T:\n",
    "    fft_result = np.fft.fft(channel_data)\n",
    "    # média da potência no intervalo de tempo sem estímulo\n",
    "    base_power = np.mean(fft_result)\n",
    "    noise_power.append(base_power)\n",
    "# média das médias de potência de todos os canais para estimar o ruído de fundo\n",
    "estimated_background_noise = np.mean(noise_power)\n",
    "print(estimated_background_noise) \n",
    "print(noise_power) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos calcular o SNR de \"banda estreita\". Pode ser observado pela seguinte equação:\n",
    "\n",
    "$SNR_{banda\\ estreita} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{média das amplitudes nas frequências vizinhas}}\\right)$\n",
    "\n",
    "Já o SNR de banda larga é definido da seguinte forma:\n",
    "\n",
    "$SNR_{banda\\ larga} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{energia total do espectro de amplitude}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "(150000, 8)\n",
      "[[-60.78499  -60.774963 -60.788536 ... -60.78455  -60.812855 -60.806137]\n",
      " [-60.779476 -60.77012  -60.8302   ... -60.791798 -60.766785 -60.7558  ]\n",
      " [-60.765987 -60.818005 -60.799507 ... -60.84719  -60.909546 -60.776447]\n",
      " ...\n",
      " [-60.882973 -60.836796 -60.68951  ... -60.72864  -60.84707  -60.899414]\n",
      " [-60.761143 -60.75759  -60.81214  ... -60.772675 -60.712753 -60.812057]\n",
      " [-60.73793  -60.77122  -60.718937 ... -60.769676 -60.7802   -60.779797]]\n",
      "(150000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12524/2533300642.py:8: RuntimeWarning: invalid value encountered in log10\n",
      "  narrow_band_SNR = 10 * np.log10(target_amplitudes_adjusted / estimated_background_noise)\n"
     ]
    }
   ],
   "source": [
    "# agora vamos adaptar ambas características \n",
    "# aplicando para o nosso sinal de interesse\n",
    "\n",
    "# forçando (estragando) valor de \"estimated_background_noise\" para não sobrar valores negativos\n",
    "target_amplitudes_adjusted = data_focus - estimated_background_noise\n",
    "\n",
    "# subtraindo o ruído de fundo das amplitudes\n",
    "narrow_band_SNR = 10 * np.log10(target_amplitudes_adjusted / estimated_background_noise)\n",
    "print(narrow_band_SNR)\n",
    "print(narrow_band_SNR.shape)\n",
    "\n",
    "total_power = np.sum(target_amplitudes_adjusted)\n",
    "wide_band_SNR = 10 * np.log10(target_amplitudes_adjusted / total_power)\n",
    "print(wide_band_SNR)\n",
    "print(wide_band_SNR.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa para aplicação das características SNR:\n",
    "\n",
    "Agora que temos os dois vetores de características SNR, podemos utilizar buffers com e sem a evocação dos rítmos que caracterizam o foco.\n",
    "\n",
    "#### Divisão dos dados\n",
    "\n",
    "Utilizando a iteração (por exemplo, de 5 segundos caracterizada pela janela) realizada no sinal a cada ~1 segundo, realize a rotulação dos dados de interesse (Beta e Gamma). Ou seja, cada amostra sera um sinal de 5 segundos (1250 pontos de 8 canais). A janela que não for qualificada como Beta ou Gama por exemplo, poderá ser rotulada com \"desfoque\". Se acharem interessante, adicionar rótulos do ritmo Theta também.\n",
    "\n",
    "No caso do sinal que representa o basal (se tiverem) poderá pegar um único sinal de aproximadamente 30 segundos para ser utilizado na equação de ruído, que irá ter como resultado um único valor. Lembrando que o valor de ruído deve atuar no sinal no domínio da frequência.\n",
    "\n",
    "#### Classificação\n",
    "\n",
    "Em nossos dados simulados, temos 150.000 pontos com 8 canais. A utilização desses dados funcionará da seguinte forma para a criação do vetor de características:\n",
    "\n",
    "- 150.000 (pontos totais) / 250 (taxa de amostragem) = 600 segundos\n",
    "- 600 / 5 (tamanho da janela sem sobreposição) = 120 amostras\n",
    "\n",
    "| 1   | SNRw1                | SNRw2 | ... | SNRw8 | SNRn1 | SNRn2 | ... | SNRn8 |\n",
    "|-----|----------------------|-------|-----|-------|-------|-------|-----|-------|\n",
    "| 2   | [w1, w2, ..., w1250] |       |     |       |       |       |     |       |\n",
    "| 3   |                      |       |     |       |       |       |     |       |\n",
    "| ... |                      |       |     |       |       |       |     |       |\n",
    "| 120 |                      |       |     |       |       |       |     |       |\n",
    "\n",
    "- Agora transforme cada um dos vetores de pontos no domínio da frequência (1250 pontos) em um único valor real. Neste caso pode ser utilizado tanto a média como a mediana (ou ambos). Se utilizarmos as duas, teremos no final 32 colunas de características:\n",
    "    - 8 canais\n",
    "    - SNR narrow e SNR wide (2)\n",
    "    - Média e mediana (2)\n",
    "\n",
    "| 1   | 1   | ... | 32 |\n",
    "|-----|-----|-----|----|\n",
    "| 2   | w'  | ... |    |\n",
    "| 3   | ... |     |    |\n",
    "| ... |     |     |    |\n",
    "| 120 |     |     |    |\n",
    "\n",
    "\n",
    "\n",
    "Após obter o vetor de característica, realizar a divisão dos dados em treinamento e teste (normalmente uma proporção de 70 e 30% respectivamente) e aplicar para o classificador SVM.\n",
    "\n",
    "**PLUS**: Ao final da tarefa, verificar a melhora dos resultados utilizando um seletor de características. Neste caso, podemos utilizar o RFE (*Recursive Feature Elimination*) em uma fase anterior a classificação para reduzir as 32 características se for necessário.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
