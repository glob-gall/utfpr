2302.00438.pdf
data: https://github.com/antonio-mastropaolo/robustness-copilot

We collected from an initial set of 1,401 open source projects
a set of 892 Java methods that are (i) accompanied by a Doc
Comment for the Javadoc tool, and (ii) exercised by a test
suite written by the project’s contributors. Then, as done in
the literature [23], [32], we considered the first sentence of
the Doc Comments as a “natural language description” of the
method. We refer to this sentence as the “original” description.

PEGASUS [66], a DL-based paraphrasing tool, and Translation Pivoting (TP), a heuristic-based approach.

Our results show that paraphrasing a description results
in a change in the code recommendation in ∼46% of cases.

2302.03287.pdf

ChatGPT is able to respond to
77.5% of the questions we examined and that, of these questions,
it is able to provide correct or partially correct answers in 55.6%
of cases, provide correct or partially correct explanations of
answers in 53.0% of cases, and that prompting the tool in a
shared question context leads to a marginally higher rate of
correct answers and explanations. Based on these findings, we
discuss the potential promises and perils related to the use of
ChatGPT by students and instructors

A fault is a static defect in the software.

An error is an in-
correct internal state, which is composed of a program counter
and the live variables at that program counter location

failure is an external, incorrect behavior with respect to the
requirements or the description of the expected behavior

we identified nine
questions that ask for material that is impossible for ChatGPT
to generate, as it is capable of generating only text-based
responses. For example, we encountered questions that ask
for a screen printout of code execution, a project to be fetched
from the internet, or a continuous integration server to be set
up. Questions with such tasks cannot be fully and correctly
answered by ChatGPT’s text-based responses.

We find that in shared contexts,
49.4% of the time the answer is correct, and 6.2% of the time it
is partially correct. In contrast, in separate contexts, responses
are correct 34.6% of the time and partially correct 7.4% of
the time. As shown in Figure 2, a shared context produces
fewer incorrect answers than separate contexts, on average.

11.8% of the time ChatGPT produces responses where
the answer-explanation pairs have different degrees of
correctness (e.g., the answer is correct, but the explana-
tion is not).

ChatGPT performed worst with questions
involving both code and concepts. It outputs correct answers
and explanations most often with coding questions (83.3%),
then with conceptual questions (55.6%), and finally with
combined questions (31.3%).


2304.11938.pdf - Is ChatGPT the Ultimate Programming Assistant - How far is it?

Evaluation Metrics
• Code correctness. To assess the correctness of generated codes
in RQ-1 and RQ-2, we rely on test cases that the benchmark pro-
vides. Any code that passes all test cases is considered correct,
while any code that fails any test case is considered incorrect.
We then use TOP-5 and AVG-5 metrics as performance measures.
Both metrics are detailed in the next section (item (2) Random-
ness).
• Code time complexity. For the RQ-1 task of code generation,
we also pay attention to the efficiency of codes. We rely on the
time-complexity-based rank percentile of code submitted to Leet-
Code as a key metric to evaluate the performance of different
code generation techniques and benchmark them against human-
written codes. More specifically, we compute the average time-
complexity-based rank percentile. If the average rank is, e.g., 10%,
this means that the generated code is among the top 10% of the
most efficient solutions.
• Repair rate. To evaluate the performance of automated program
repair tools in RQ-2, we leverage the standard metric of repair
rate, i.e. the ratio of the patched codes generated by approaches

2305.11837.pdf
metrichs: runtime & memory - C OMPARING S OFTWARE D EVELOPERS WITH C HAT GPT:A N E MPIRICAL I NVESTIGATION
304.11938.pdf - Is ChatGPT the Ultimate Programming Assistant - How far is it?

Long description inputs (i.e, lengthy prompts) appear to have a
negative impact on the code generation of ChatGPT and Codex.



2305.11837.pdf - COMPARING SOFTWARE DEVELOPERS WITH CHATGPT: AN EMPIRICAL INVESTIGATION

“ChatGPT has been estimated
to consume the equivalent of the electricity consumed by 175,000 people in Denmark per month"

ChatGPT-generated code versus code produced by developers and uploaded in Leetcode, which consists
of three steps: 
(i) we selected a contest from Leetcode that contains programming problems at different difficulty levels;
(ii) we used these problems as prompts to ChatGPT to generate code; and 
(iii) we uploaded the ChatGPT code solution
to Leetcode and compared them to the previous solutions based on performance and efficiency metrics.

For almost 76 years, researchers have been writing about the concept of “automatic programming" [20].

OpenAI’s Codex - Accordingly, after generating 100 samples per problem, their solution was able to solve 77.5% of the
problems. They evaluated their approach based on efficacy (number of tests passed), not accessing performance,
and memory efficiency. Imai [7], and Nguyen and Nadi [17] also performed empirical studies with a version of
Codex. The non-functional requirements they evaluated are productivity, code quality, confiability, correctness, and
understandability. We describe their findings in Section 2.

H0. ChatGPT does not improve the performance of coding solutions compared to solutions provided by
experienced contest programmers.
• HA. ChatGPT improves the performance of coding solutions compared to solutions provided by experienced
contest programmers.
